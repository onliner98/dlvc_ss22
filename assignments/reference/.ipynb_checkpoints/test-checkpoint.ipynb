{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc2cfe8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xshape, yshape, len, n class:  (7959, 32, 32, 3) (7959,) 7959 2\n",
      "dtype X,y:  uint8 int64\n",
      "sample:  Sample(idx=0, data=array([[[116, 125, 125],\n",
      "        [ 91, 101, 110],\n",
      "        [ 83,  90, 102],\n",
      "        ...,\n",
      "        [214, 207, 202],\n",
      "        [212, 205, 200],\n",
      "        [214, 208, 202]],\n",
      "\n",
      "       [[142, 146, 142],\n",
      "        [139, 144, 146],\n",
      "        [170, 172, 176],\n",
      "        ...,\n",
      "        [205, 201, 195],\n",
      "        [209, 205, 198],\n",
      "        [215, 211, 204]],\n",
      "\n",
      "       [[183, 185, 180],\n",
      "        [146, 146, 143],\n",
      "        [157, 157, 156],\n",
      "        ...,\n",
      "        [113, 111, 122],\n",
      "        [131, 128, 139],\n",
      "        [150, 147, 158]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  82, 104],\n",
      "        [ 39,  80, 101],\n",
      "        [ 38,  81, 101],\n",
      "        ...,\n",
      "        [ 67, 103, 126],\n",
      "        [ 69, 103, 126],\n",
      "        [ 68, 101, 125]],\n",
      "\n",
      "       [[ 40,  81, 104],\n",
      "        [ 41,  84, 105],\n",
      "        [ 43,  88, 109],\n",
      "        ...,\n",
      "        [ 78, 113, 138],\n",
      "        [ 80, 113, 137],\n",
      "        [ 81, 112, 137]],\n",
      "\n",
      "       [[ 42,  83, 105],\n",
      "        [ 45,  87, 108],\n",
      "        [ 50,  94, 115],\n",
      "        ...,\n",
      "        [ 82, 117, 143],\n",
      "        [ 84, 116, 143],\n",
      "        [ 86, 116, 144]]], dtype=uint8), label=0)\n",
      "y.  [0 0 0 0 1 0 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from dlvc.datasets.pets import PetsDataset, Subset\n",
    "from assignments.src.dlvc import ops\n",
    "from assignments.src.dlvc.batches import BatchGenerator\n",
    "from assignments.src.dlvc.dataset import Dataset, ClassificationDataset\n",
    "\n",
    "fdir = '/mnt/1028D91228D8F7A4/Python Project/PycharmProjects/DeepLearning/assignments/src/cifar10'\n",
    "pds = PetsDataset(fdir, Subset.TRAINING)\n",
    "print('Xshape, yshape, len, n class: ', pds.X.shape, pds.y.shape, len(pds), pds.num_classes())\n",
    "print('dtype X,y: ', pds.X.dtype, pds.y.dtype)\n",
    "print('sample: ', pds[0])\n",
    "print('y. ', pds.y[0:10])\n",
    "\n",
    "cv2.imwrite('sample.png', pds[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6e47886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test part 2 assignment 1\n",
    "op = ops.chain([\n",
    "    ops.vectorize(),\n",
    "    ops.type_cast(np.float32),\n",
    "    ops.add(-127.5),\n",
    "    ops.mul(1/127.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9511acdb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid type for dataset. Expected:<class 'assignments.src.dlvc.dataset.Dataset'>. Provided:<class 'dlvc.datasets.pets.PetsDataset'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-51c99fd94894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPetsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/1028D91228D8F7A4/Python Project/PycharmProjects/DeepLearning/assignments/src/dlvc/batches.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, num, shuffle, op)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Invalid type for dataset. Expected:{Dataset}. Provided:{type(dataset)}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Invalid type argument for num. Expected:{int}. Provided:{type(num)}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid type for dataset. Expected:<class 'assignments.src.dlvc.dataset.Dataset'>. Provided:<class 'dlvc.datasets.pets.PetsDataset'>."
     ]
    }
   ],
   "source": [
    "train_ds = PetsDataset(fdir, Subset.TRAINING)\n",
    "bg = BatchGenerator(train_ds, 10, False, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e6354-9975-499d-882f-79fd1cec3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlvc.datasets.pets import PetsDataset\n",
    "from dlvc.dataset import Subset\n",
    "from dlvc.batches import BatchGenerator\n",
    "from dlvc.test import Accuracy\n",
    "import dlvc.ops as ops\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# TODO: Define the network architecture of your linear classifier.\n",
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # define network layer\n",
    "        self.layer = torch.nn.Linear(self.input_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "op = ops.chain([\n",
    "    ops.vectorize(),\n",
    "    ops.type_cast(np.float32),\n",
    "    ops.add(-127.5),\n",
    "    ops.mul(1 / 127.5),\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(linear_classifier, criterion, optimizer, epochs, train_data, valid_data):\n",
    "    acc = Accuracy()\n",
    "    print(\"Train the network\")\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        acc.reset()\n",
    "        for data in train_data:\n",
    "            # get the inputs and the labels\n",
    "            inputs = data.data\n",
    "            labels = data.label\n",
    "\n",
    "            # convert the np.array in tensor\n",
    "            t_inputs = torch.tensor(inputs)\n",
    "            t_labels = torch.tensor(labels).to(torch.long) #cast labels to long so the CE works (CE throws exception with int)\n",
    "\n",
    "            # zero the parameter gradients, for every batch I must compute the gradient again\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward step\n",
    "            output = linear_classifier.forward(t_inputs)\n",
    "            loss = criterion(output, t_labels)\n",
    "            loss.backward()  # compute the gradients\n",
    "            optimizer.step()  # update the parameter\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            acc.update(linear_classifier.forward(torch.tensor(valid_data.data)).detach().numpy(), valid_data.label)\n",
    "            print(f\"epoch {epoch + 1} \\ntrain loss: {running_loss}\\nval accuracy: {acc.accuracy()}\")\n",
    "\n",
    "            # update the values\n",
    "            running_loss = 0.0\n",
    "            if acc.accuracy() >= best_acc:\n",
    "                best_acc = acc.accuracy()\n",
    "\n",
    "            acc.reset()\n",
    "    print(\"Finished Training\")\n",
    "    return linear_classifier, best_acc\n",
    "\n",
    "\n",
    "def main():\n",
    "    fp = 'C:/Users/admin/Desktop/10. Semester/Computer Vision/dlvc_ss22/assignments/reference/cifar10'\n",
    "\n",
    "    print(\"Load data\")\n",
    "    train_ds = PetsDataset(fp, Subset.TRAINING)\n",
    "    valid_ds = PetsDataset(fp, Subset.VALIDATION)\n",
    "    test_ds = PetsDataset(fp, Subset.TEST)\n",
    "    print(\"Data Loaded\")\n",
    "\n",
    "    print(\"Creating Batch Generator\")\n",
    "    train = BatchGenerator(train_ds, len(train_ds), False, op)\n",
    "    valid = next(iter(BatchGenerator(valid_ds, len(valid_ds), False, op)))\n",
    "    test = next(iter(BatchGenerator(test_ds, len(test_ds), False, op)))\n",
    "    print(\"Batch Generator created\")\n",
    "\n",
    "    #define general parameters\n",
    "    in_features = 3072  # size of the vector in input\n",
    "    epochs = 100\n",
    "\n",
    "    #Test 1\n",
    "    print(\"Create Linear Classifier, Loss Function and Optimizer\")\n",
    "    lc = LinearClassifier(in_features, train_ds.num_classes())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(lc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    lc_test_1, best_acc_test1 = train_model(lc, criterion, optimizer, epochs, train, valid)\n",
    "\n",
    "    #Test 2, change the optimizer\n",
    "    print(\"------------------------------------\")\n",
    "    lc = LinearClassifier(in_features, train_ds.num_classes())\n",
    "    optimizer = torch.optim.Adam(lc.parameters(), lr=0.001)\n",
    "    lc_test_2, best_acc_test2 = train_model(lc, criterion, optimizer, epochs, train, valid)\n",
    "\n",
    "    #find the best model\n",
    "    if best_acc_test1 > best_acc_test2:\n",
    "        lc = lc_test_1\n",
    "        best_acc = best_acc_test1\n",
    "    else:\n",
    "        lc = lc_test_2\n",
    "        best_acc = best_acc_test2\n",
    "\n",
    "    print(\"--------------------\")\n",
    "    print(f\"val accuracy (best): {best_acc}\")\n",
    "\n",
    "    # compute the test accuracy\n",
    "    test_acc = Accuracy()\n",
    "    test_acc.update(lc.forward(torch.tensor(test.data)).detach().numpy(), test.label)\n",
    "    print(f\"test accuracy: {test_acc.accuracy()}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
