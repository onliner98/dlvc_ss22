{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "736d9873-9543-490a-be6e-6c83436665fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Assignemt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16618f-a895-4968-89dd-e9908b77e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from dlvc.datasets.pets import PetsDataset, Subset\n",
    "from assignments.src.dlvc import ops\n",
    "from assignments.src.dlvc.batches import BatchGenerator\n",
    "from assignments.src.dlvc.dataset import Dataset, ClassificationDataset\n",
    "\n",
    "fdir = '/mnt/1028D91228D8F7A4/Python Project/PycharmProjects/DeepLearning/assignments/src/cifar10'\n",
    "pds = PetsDataset(fdir, Subset.TRAINING)\n",
    "print('Xshape, yshape, len, n class: ', pds.X.shape, pds.y.shape, len(pds), pds.num_classes())\n",
    "print('dtype X,y: ', pds.X.dtype, pds.y.dtype)\n",
    "print('sample: ', pds[0])\n",
    "print('y. ', pds.y[0:10])\n",
    "\n",
    "cv2.imwrite('sample.png', pds[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e47886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test part 2 assignment 1\n",
    "op = ops.chain([\n",
    "    ops.vectorize(),\n",
    "    ops.type_cast(np.float32),\n",
    "    ops.add(-127.5),\n",
    "    ops.mul(1/127.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511acdb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = PetsDataset(fdir, Subset.TRAINING)\n",
    "bg = BatchGenerator(train_ds, 10, False, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e6354-9975-499d-882f-79fd1cec3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlvc.datasets.pets import PetsDataset\n",
    "from dlvc.dataset import Subset\n",
    "from dlvc.batches import BatchGenerator\n",
    "from dlvc.test import Accuracy\n",
    "import dlvc.ops as ops\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# TODO: Define the network architecture of your linear classifier.\n",
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # define network layer\n",
    "        self.layer = torch.nn.Linear(self.input_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "op = ops.chain([\n",
    "    ops.vectorize(),\n",
    "    ops.type_cast(np.float32),\n",
    "    ops.add(-127.5),\n",
    "    ops.mul(1 / 127.5),\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(linear_classifier, criterion, optimizer, epochs, train_data, valid_data):\n",
    "    acc = Accuracy()\n",
    "    print(\"Train the network\")\n",
    "    accs = np.zeros(epochs)\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        acc.reset()\n",
    "        for data in train_data:\n",
    "            # get the inputs and the labels\n",
    "            inputs = data.data\n",
    "            labels = data.label\n",
    "\n",
    "            # convert the np.array in tensor\n",
    "            t_inputs = torch.tensor(inputs)\n",
    "            t_labels = torch.tensor(labels).to(torch.long) #cast labels to long so the CE works (CE throws exception with int)\n",
    "\n",
    "            # zero the parameter gradients, for every batch I must compute the gradient again\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward step\n",
    "            output = linear_classifier.forward(t_inputs)\n",
    "            loss = criterion(output, t_labels)\n",
    "            loss.backward()  # compute the gradients\n",
    "            optimizer.step()  # update the parameter\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            acc.update(linear_classifier.forward(torch.tensor(valid_data.data)).detach().numpy(), valid_data.label)\n",
    "            print(f\"epoch {epoch + 1} \\ntrain loss: {running_loss}\\nval accuracy: {acc.accuracy()}\")\n",
    "            accs[epoch] = acc.accuracy()\n",
    "            \n",
    "            # update the values\n",
    "            running_loss = 0.0\n",
    "            if acc.accuracy() >= best_acc:\n",
    "                best_acc = acc.accuracy()\n",
    "\n",
    "            acc.reset()\n",
    "    print(\"Finished Training\")\n",
    "    return linear_classifier, best_acc, accs\n",
    "\n",
    "\n",
    "def main():\n",
    "    fp = 'C:/Users/admin/Desktop/10. Semester/Computer Vision/dlvc_ss22/assignments/reference/cifar10'\n",
    "\n",
    "    print(\"Load data\")\n",
    "    train_ds = PetsDataset(fp, Subset.TRAINING)\n",
    "    valid_ds = PetsDataset(fp, Subset.VALIDATION)\n",
    "    test_ds = PetsDataset(fp, Subset.TEST)\n",
    "    print(\"Data Loaded\")\n",
    "\n",
    "    print(\"Creating Batch Generator\")\n",
    "    train = BatchGenerator(train_ds, len(train_ds), False, op)\n",
    "    valid = next(iter(BatchGenerator(valid_ds, len(valid_ds), False, op)))\n",
    "    test = next(iter(BatchGenerator(test_ds, len(test_ds), False, op)))\n",
    "    print(\"Batch Generator created\")\n",
    "\n",
    "    #define general parameters\n",
    "    in_features = 3072  # size of the vector in input\n",
    "    epochs = 100\n",
    "\n",
    "    lc = LinearClassifier(in_features, train_ds.num_classes())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(lc.parameters(), lr=0.001)\n",
    "    lc, best_val_acc, val_accs = train_model(lc, criterion, optimizer, epochs, train, valid)\n",
    "\n",
    "\n",
    "    # compute the test accuracy\n",
    "    test_acc = Accuracy()\n",
    "    test_acc.update(lc.forward(torch.tensor(test.data)).detach().numpy(), test.label)\n",
    "    print(f\"test accuracy: {test_acc.accuracy()}\")\n",
    "    \n",
    "    return val_accs, best_val_acc, test_acc\n",
    "\n",
    "\n",
    "val_accs, best_val_acc, test_acc = main()\n",
    "print(val_accs, best_val_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9144f7-c16e-4126-888b-678c6277100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(val_accs)\n",
    "plt.xlabel('Validation Accuracy')\n",
    "plt.ylabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54256b7-ea33-45cb-9291-382e89edf838",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240eddc5-0b9e-40be-af6b-ead5976bf965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, c_in: int, c_out: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(c_in, c_out, 3, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(c_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(c_out, c_in, 3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(c_out)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_channels, n_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, 3, padding='same')\n",
    "        self.block1 = ResBlock(64,64)\n",
    "        self.downsample1 = nn.Conv2d(64, 128, 3, stride=2)\n",
    "        self.block2 = ResBlock(128,128)\n",
    "        self.downsample2 = nn.Conv2d(128, 256, 3, stride=2)\n",
    "        self.block3 = ResBlock(256,256)\n",
    "        self.fc = nn.Linear(12544, n_classes) # TODO change 400 to correct\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.block3(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e66df6-e225-4bb8-b84f-d2fcefe3b7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train loss: 1.103727174183679 ± 0.5451035468071038\n",
      "val acc: 0.4977951984321411\n",
      "epoch 1\n",
      "train loss: 0.6950364037165566 ± 0.006131209468592341\n",
      "val acc: 0.4977951984321411\n",
      "epoch 2\n",
      "train loss: 0.6905534797244601 ± 0.007104778060515808\n",
      "val acc: 0.512983831455169\n",
      "epoch 3\n",
      "train loss: 0.6831457633820791 ± 0.011841955183205119\n",
      "val acc: 0.5590396864282214\n",
      "epoch 4\n",
      "train loss: 0.6740419136153327 ± 0.01739311971511226\n",
      "val acc: 0.5918667319941205\n",
      "epoch 5\n",
      "train loss: 0.6666214390406533 ± 0.01957517401615726\n",
      "val acc: 0.6050955414012739\n",
      "epoch 6\n",
      "train loss: 0.6596668504533314 ± 0.02245154883965912\n",
      "val acc: 0.622733953944145\n",
      "epoch 7\n",
      "train loss: 0.6561755850201562 ± 0.024370831389295047\n",
      "val acc: 0.6266536011758942\n",
      "epoch 8\n",
      "train loss: 0.6527470208349682 ± 0.026235492758105716\n",
      "val acc: 0.622733953944145\n",
      "epoch 9\n",
      "train loss: 0.6507221081900219 ± 0.026508966451239072\n",
      "val acc: 0.6330230279274865\n",
      "epoch 10\n",
      "train loss: 0.648326125409868 ± 0.02730340429748494\n",
      "val acc: 0.6340029397354238\n",
      "epoch 11\n",
      "train loss: 0.6456786479268756 ± 0.027114795751593014\n",
      "val acc: 0.6408623223909848\n",
      "epoch 12\n",
      "train loss: 0.6441860738254729 ± 0.0281114890894978\n",
      "val acc: 0.6393924546790789\n",
      "epoch 13\n",
      "train loss: 0.6420224838786655 ± 0.028523550897851035\n",
      "val acc: 0.6491915727584517\n",
      "epoch 14\n",
      "train loss: 0.6391194803374154 ± 0.029554138978167117\n",
      "val acc: 0.6536011758941696\n",
      "epoch 15\n",
      "train loss: 0.6372046943694826 ± 0.029609121555184803\n",
      "val acc: 0.6521313081822636\n",
      "epoch 16\n",
      "train loss: 0.6337269355380346 ± 0.030380944338608728\n",
      "val acc: 0.6536011758941696\n",
      "epoch 17\n",
      "train loss: 0.6314992545143007 ± 0.030590932527742885\n",
      "val acc: 0.6555609995100441\n",
      "epoch 18\n",
      "train loss: 0.6281879733479212 ± 0.02993570941373624\n",
      "val acc: 0.6565409113179814\n",
      "epoch 19\n",
      "train loss: 0.6265108538052392 ± 0.031961675606972245\n",
      "val acc: 0.6599706026457619\n",
      "epoch 20\n",
      "train loss: 0.6237962047259012 ± 0.031432060306466024\n",
      "val acc: 0.6589906908378246\n",
      "epoch 21\n",
      "train loss: 0.6205702613270472 ± 0.03148744498858244\n",
      "val acc: 0.6604605585497305\n",
      "epoch 22\n",
      "train loss: 0.6183708887251597 ± 0.0313927387411709\n",
      "val acc: 0.6658500734933855\n",
      "epoch 23\n",
      "train loss: 0.6165528354190645 ± 0.03276717185079579\n",
      "val acc: 0.6712395884370407\n",
      "epoch 24\n",
      "train loss: 0.6116965025190323 ± 0.0321200200145762\n",
      "val acc: 0.6761391474767271\n",
      "epoch 25\n",
      "train loss: 0.6074599396614802 ± 0.03387898591878135\n",
      "val acc: 0.6594806467417932\n",
      "epoch 26\n",
      "train loss: 0.602536988636804 ± 0.033188938814214676\n",
      "val acc: 0.6785889269965704\n",
      "epoch 27\n",
      "train loss: 0.6021122402615018 ± 0.0334202109497068\n",
      "val acc: 0.6682998530132288\n",
      "epoch 28\n",
      "train loss: 0.5959617296854655 ± 0.03412697505310619\n",
      "val acc: 0.6815286624203821\n",
      "epoch 29\n",
      "train loss: 0.5935057098903354 ± 0.03240269155414632\n",
      "val acc: 0.6751592356687898\n",
      "epoch 30\n",
      "train loss: 0.5893427407930768 ± 0.03674394480494255\n",
      "val acc: 0.6864282214600685\n",
      "epoch 31\n",
      "train loss: 0.5860644124803089 ± 0.03641785137809679\n",
      "val acc: 0.6883880450759432\n",
      "epoch 32\n",
      "train loss: 0.5808590589061616 ± 0.037044336166017454\n",
      "val acc: 0.6800587947084762\n",
      "epoch 33\n",
      "train loss: 0.5764520362256065 ± 0.03684599130571352\n",
      "val acc: 0.6771190592846644\n",
      "epoch 34\n",
      "train loss: 0.5742055097269634 ± 0.03579183633613816\n",
      "val acc: 0.6785889269965704\n",
      "epoch 35\n",
      "train loss: 0.5700108035216256 ± 0.0375076478340202\n",
      "val acc: 0.6805487506124449\n",
      "epoch 36\n",
      "train loss: 0.5687091218100654 ± 0.03791875557958173\n",
      "val acc: 0.6962273395394415\n",
      "epoch 37\n",
      "train loss: 0.5631926476009308 ± 0.03770843521650317\n",
      "val acc: 0.6849583537481627\n",
      "epoch 38\n",
      "train loss: 0.5622942523350791 ± 0.0384738135314738\n",
      "val acc: 0.6854483096521313\n",
      "epoch 39\n",
      "train loss: 0.5562072301667834 ± 0.03751174949153382\n",
      "val acc: 0.6888780009799118\n",
      "epoch 40\n",
      "train loss: 0.5591374612043775 ± 0.04174259456993179\n",
      "val acc: 0.7011268985791279\n",
      "epoch 41\n",
      "train loss: 0.5513402956818777 ± 0.04053818044429711\n",
      "val acc: 0.6937775600195982\n",
      "epoch 42\n",
      "train loss: 0.5516402366615477 ± 0.04238909484166778\n",
      "val acc: 0.6942675159235668\n",
      "epoch 43\n",
      "train loss: 0.549466651110422 ± 0.03865554880218957\n",
      "val acc: 0.7094561489465948\n",
      "epoch 44\n",
      "train loss: 0.5465863507891459 ± 0.038171391867214646\n",
      "val acc: 0.6947574718275356\n",
      "epoch 45\n",
      "train loss: 0.5432356548687768 ± 0.03862105462144322\n",
      "val acc: 0.698187163155316\n",
      "epoch 46\n",
      "train loss: 0.5438121533583081 ± 0.040503578057555896\n",
      "val acc: 0.6972072513473787\n",
      "epoch 47\n",
      "train loss: 0.5405719157249208 ± 0.03990494740183443\n",
      "val acc: 0.7070063694267515\n",
      "epoch 48\n",
      "train loss: 0.5392682840899815 ± 0.040631475337471246\n",
      "val acc: 0.6952474277315042\n",
      "epoch 49\n",
      "train loss: 0.5343748051968832 ± 0.03888858280628585\n",
      "val acc: 0.7055365017148456\n",
      "epoch 50\n",
      "train loss: 0.5362853691691444 ± 0.0392203278499418\n",
      "val acc: 0.7001469867711906\n",
      "epoch 51\n",
      "train loss: 0.5313632715316046 ± 0.03974136508397959\n",
      "val acc: 0.698187163155316\n",
      "epoch 52\n",
      "train loss: 0.5296602996568831 ± 0.04069918766265632\n",
      "val acc: 0.698187163155316\n",
      "epoch 53\n",
      "train loss: 0.528151747253206 ± 0.0388788588258684\n",
      "val acc: 0.6780989710926016\n",
      "epoch 54\n",
      "train loss: 0.5265390404633113 ± 0.039727037282339485\n",
      "val acc: 0.7099461048505634\n",
      "epoch 55\n",
      "train loss: 0.5212807116054353 ± 0.03915889047890297\n",
      "val acc: 0.6991670749632533\n",
      "epoch 56\n",
      "train loss: 0.5205636663096291 ± 0.04293324534419214\n",
      "val acc: 0.6927976482116609\n",
      "epoch 57\n",
      "train loss: 0.5182797464113387 ± 0.04176123659508264\n",
      "val acc: 0.6893679568838804\n",
      "epoch 58\n",
      "train loss: 0.5176789093585241 ± 0.04381541426380141\n",
      "val acc: 0.6913277804997551\n",
      "epoch 59\n",
      "train loss: 0.5191444536996266 ± 0.04021448705773438\n",
      "val acc: 0.7040666340029398\n",
      "epoch 60\n",
      "train loss: 0.5110857288042704 ± 0.04332732867715036\n",
      "val acc: 0.7030867221950025\n",
      "epoch 61\n",
      "train loss: 0.5115171046484084 ± 0.045820200964544165\n",
      "val acc: 0.7045565899069084\n",
      "epoch 62\n",
      "train loss: 0.5093554660441384 ± 0.04335339926550628\n",
      "val acc: 0.7074963253307203\n",
      "epoch 63\n",
      "train loss: 0.5049653682443831 ± 0.04168155209981716\n",
      "val acc: 0.6976972072513474\n",
      "epoch 64\n",
      "train loss: 0.506965983954687 ± 0.04445630768708258\n",
      "val acc: 0.7060264576188143\n",
      "epoch 65\n",
      "train loss: 0.4987239269983201 ± 0.04306272150115453\n",
      "val acc: 0.7114159725624694\n",
      "epoch 66\n",
      "train loss: 0.5031691576753344 ± 0.0456843235267932\n",
      "val acc: 0.7143557079862812\n",
      "epoch 67\n",
      "train loss: 0.49967949872925166 ± 0.04612522546713661\n",
      "val acc: 0.7060264576188143\n",
      "epoch 68\n",
      "train loss: 0.4985037214226193 ± 0.0489973585910051\n",
      "val acc: 0.699657030867222\n",
      "epoch 69\n",
      "train loss: 0.4989961310038491 ± 0.04733224791287603\n",
      "val acc: 0.7084762371386575\n",
      "epoch 70\n",
      "train loss: 0.4963387908443572 ± 0.044529245972949216\n",
      "val acc: 0.7153356197942186\n",
      "epoch 71\n",
      "train loss: 0.4905919446831658 ± 0.046835899858326195\n",
      "val acc: 0.7104360607545321\n",
      "epoch 72\n",
      "train loss: 0.49038029379314846 ± 0.04695201326136313\n",
      "val acc: 0.7212150906418422\n",
      "epoch 73\n",
      "train loss: 0.48688292739883304 ± 0.04760425040422009\n",
      "val acc: 0.7011268985791279\n",
      "epoch 74\n",
      "train loss: 0.4814059067340124 ± 0.04756145562993012\n",
      "val acc: 0.7207251347378736\n",
      "epoch 75\n",
      "train loss: 0.48470715350574917 ± 0.04588786803788762\n",
      "val acc: 0.7119059284664381\n",
      "epoch 76\n",
      "train loss: 0.47834650344318813 ± 0.04781675557920166\n",
      "val acc: 0.7153356197942186\n",
      "epoch 77\n",
      "train loss: 0.47475174968204803 ± 0.046214436343933823\n",
      "val acc: 0.7104360607545321\n",
      "epoch 78\n",
      "train loss: 0.47011437066017636 ± 0.04982303060764809\n",
      "val acc: 0.7143557079862812\n",
      "epoch 79\n",
      "train loss: 0.46728719321508255 ± 0.0480588500252763\n",
      "val acc: 0.7099461048505634\n",
      "epoch 80\n",
      "train loss: 0.47301587415119956 ± 0.05593789568868561\n",
      "val acc: 0.7148456638902498\n",
      "epoch 81\n",
      "train loss: 0.4645211133692 ± 0.0468115502369089\n",
      "val acc: 0.7153356197942186\n",
      "epoch 82\n",
      "train loss: 0.4681309452132573 ± 0.058323764630546386\n",
      "val acc: 0.7143557079862812\n",
      "epoch 83\n",
      "train loss: 0.4602438381740025 ± 0.04867317295089272\n",
      "val acc: 0.7133757961783439\n",
      "epoch 84\n",
      "train loss: 0.45816381583138116 ± 0.04808339191415748\n",
      "val acc: 0.72562469377756\n",
      "epoch 85\n",
      "train loss: 0.4561907686884441 ± 0.049360597948331954\n",
      "val acc: 0.7261146496815286\n",
      "epoch 86\n",
      "train loss: 0.4540305175478496 ± 0.05341938735748689\n",
      "val acc: 0.7109260166585007\n",
      "epoch 87\n",
      "train loss: 0.44500014043989633 ± 0.05295320555633692\n",
      "val acc: 0.7280744732974033\n",
      "epoch 88\n",
      "train loss: 0.4533672302015244 ± 0.06813156070492102\n",
      "val acc: 0.7030867221950025\n",
      "epoch 89\n",
      "train loss: 0.44570318337470766 ± 0.05325467249181931\n",
      "val acc: 0.7104360607545321\n",
      "epoch 90\n",
      "train loss: 0.44398448391566203 ± 0.053098215441121754\n",
      "val acc: 0.7104360607545321\n",
      "epoch 91\n",
      "train loss: 0.4481730390162695 ± 0.08364604654617636\n",
      "val acc: 0.7119059284664381\n",
      "epoch 92\n",
      "train loss: 0.4336319523198264 ± 0.05216124511733918\n",
      "val acc: 0.7143557079862812\n",
      "epoch 93\n",
      "train loss: 0.42941166886261534 ± 0.051578850174289974\n",
      "val acc: 0.7114159725624694\n",
      "epoch 94\n",
      "train loss: 0.4353072548669482 ± 0.055489499891912195\n",
      "val acc: 0.7060264576188143\n",
      "epoch 95\n",
      "train loss: 0.431030649277899 ± 0.05676519144393602\n",
      "val acc: 0.7241548260656541\n",
      "epoch 96\n",
      "train loss: 0.429389598823729 ± 0.06755567322980818\n",
      "val acc: 0.7172954434100931\n",
      "epoch 97\n",
      "train loss: 0.4295713506520741 ± 0.06671845818830716\n",
      "val acc: 0.7094561489465948\n",
      "epoch 98\n",
      "train loss: 0.4242975087392898 ± 0.07069654450229577\n",
      "val acc: 0.7148456638902498\n",
      "epoch 99\n",
      "train loss: 0.4216496097663092 ± 0.06343661525413691\n",
      "val acc: 0.7099461048505634\n",
      "--------------------\n",
      "val acc (best): 0.7099461048505634\n",
      "test acc: 0.712\n",
      "[['cnn_low_wd_and_hf', 0.7099461048505634, 0.712]]\n"
     ]
    }
   ],
   "source": [
    "from dlvc.datasets.pets import PetsDataset\n",
    "from dlvc.dataset import Subset\n",
    "from dlvc.batches import BatchGenerator\n",
    "from dlvc.test import Accuracy\n",
    "import dlvc.ops as ops\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from dlvc.models.pytorch import CnnClassifier\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, c_in) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        self.conv1 = nn.Conv2d(c_in, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(576, 120)  # 400 ergibt sich bei input image 28x28\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def run_experiment(fp, net, name, n_epochs, batch_size, input_shape, num_classes, shuffle, lr, wd, op):\n",
    "    train_ds = PetsDataset(fp, Subset.TRAINING)\n",
    "    valid_ds = PetsDataset(fp, Subset.VALIDATION)\n",
    "    test_ds = PetsDataset(fp, Subset.TEST)\n",
    "\n",
    "    train = BatchGenerator(train_ds, batch_size, shuffle, op)\n",
    "    valid = BatchGenerator(valid_ds, batch_size, shuffle, op)\n",
    "    test = BatchGenerator(test_ds, batch_size, shuffle, op)\n",
    "\n",
    "    model = CnnClassifier(net, input_shape, num_classes, lr, wd)\n",
    "    acc = Accuracy()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        losses = []\n",
    "        best_acc = 0\n",
    "        # Training Loop\n",
    "        for data in train:\n",
    "            loss = model.train(data.data, data.label)\n",
    "            losses.append(loss)\n",
    "        # Validation Loop\n",
    "        acc.reset()\n",
    "        for data in valid:\n",
    "            pred = model.predict(data.data)\n",
    "            acc.update(pred, data.label)\n",
    "\n",
    "        # Reporting\n",
    "        losses = np.array(losses)\n",
    "\n",
    "        print('epoch', epoch)\n",
    "        print('train loss:', losses.mean(), '±', losses.std())\n",
    "        print('val acc:', acc.accuracy())\n",
    "\n",
    "        if acc.accuracy() > best_acc:\n",
    "            torch.save(model, f'best_{name}.pth')\n",
    "            best_acc = acc.accuracy()\n",
    "\n",
    "    model = torch.load(f'best_{name}.pth')\n",
    "    acc.reset()\n",
    "    for data in test:\n",
    "        pred = model.predict(data.data)\n",
    "        acc.update(pred, data.label)\n",
    "    print('--------------------')\n",
    "    print('val acc (best):', best_acc)\n",
    "    print('test acc:', acc.accuracy())\n",
    "    return best_acc, acc.accuracy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "op_no_da = ops.chain([\n",
    "    ops.type_cast(np.float32),\n",
    "    ops.add(-127.5),\n",
    "    ops.mul(1 / 127.5),\n",
    "    ops.hwc2chw(),\n",
    "])\n",
    "\n",
    "op_da = ops.chain([\n",
    "    ops.type_cast(np.float32),\n",
    "    ops.add(-127.5),\n",
    "    ops.mul(1 / 127.5),\n",
    "    ops.hflip(),\n",
    "    ops.hwc2chw(),\n",
    "])\n",
    "\n",
    "# try neither, only wd weak, only wd medium, only wd overreg, only da, both\n",
    "# a config contains [wd, ops]\n",
    "configs = [\n",
    "    [0.01, op_da, 'cnn_low_wd_and_hf']\n",
    "]\n",
    "\n",
    "# Constants\n",
    "fp = 'C:/Users/admin/Desktop/10. Semester/Computer Vision/dlvc_ss22/assignments/reference/cifar10'\n",
    "n_epochs = 100\n",
    "batch_size=128\n",
    "input_shape = (0, 3, 32, 32)\n",
    "num_classes = 2\n",
    "shuffle = True\n",
    "lr = 0.01\n",
    "\n",
    "net = CNN(input_shape[1])\n",
    "# move to cuda if available\n",
    "net.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "results = []\n",
    "for wd, op, name in configs:\n",
    "    best_val_acc, test_acc = run_experiment(fp, net, name, n_epochs, batch_size, input_shape, num_classes, shuffle, lr, wd, op)\n",
    "    results.append([name, best_val_acc, test_acc])\n",
    "    \n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
